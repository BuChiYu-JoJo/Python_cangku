import aiohttp
import asyncio
import time
import os
import logging
from urllib.parse import quote
from statistics import mean
from datetime import datetime

# ========== é…ç½® ==========
SEARCH_TERMS = ["Apple", "Bread", "Cheese", "Salmon", "Chocolate",
                "Spinach", "Yogurt", "Pasta", "Almond", "Eggplant"]

SEARCH_ENGINES = ["google", "bing", "yandex", "duckduckgo"]

TIMEOUT_SECONDS = 60
MIN_CONTENT_SIZE_KB = 10
CONCURRENCY = 10
RUN_DURATION_SECONDS = 150
SCHEDULE_INTERVAL = 300

SAVE_EMPTY_RESPONSE = False
ENABLE_SAVE_RESPONSE = False
ENABLE_CONSOLE_LOG = False
ENABLE_FILE_LOG = True

DINGTALK_WEBHOOK = "https://oapi.dingtalk.com/robot/send?access_token=e05a6891a68b9b3b1cfacf8dcf5852bf647457439261362fac0a1e096951bfa9"
DINGTALK_KEYWORD = "test"

# ========== ä¸»è¿è¡Œæ—¥å¿—ï¼ˆä»…è®°å½•æµç¨‹ï¼‰ ==========
main_logger = logging.getLogger("main")
main_logger.setLevel(logging.INFO)
if ENABLE_FILE_LOG:
    file_handler = logging.FileHandler("run.log", mode="a", encoding="utf-8")
    file_handler.setFormatter(logging.Formatter("%(asctime)s - %(message)s", datefmt="%Y-%m-%d %H:%M:%S"))
    main_logger.addHandler(file_handler)


def log_print(message):
    if ENABLE_CONSOLE_LOG:
        print(message)
    if ENABLE_FILE_LOG:
        main_logger.info(message)


# ========== ç‹¬ç«‹å¼•æ“æ—¥å¿— ==========
def get_engine_logger(engine: str, ts_folder: str):
    os.makedirs(f"logs/{engine}", exist_ok=True)
    logger = logging.getLogger(f"{engine}_{ts_folder}")
    logger.setLevel(logging.INFO)
    if not logger.handlers:
        handler = logging.FileHandler(f"logs/{engine}/{ts_folder}.log", mode="w", encoding="utf-8")
        handler.setFormatter(logging.Formatter("%(asctime)s - %(message)s", datefmt="%Y-%m-%d %H:%M:%S"))
        logger.addHandler(handler)
    return logger


# ========== å¼•æ“é…ç½® ==========
ENGINE_DOMAINS = {
    "google": "www.google.com",
    "bing": "www.bing.com",
    "yandex": "yandex.com",
    "duckduckgo": "duckduckgo.com"
}

def build_service_config(engine):
    domain = ENGINE_DOMAINS[engine]
    return {
        'url': "https://scraperapi.thordata.com/request",
        'method': 'POST',
        'headers': {
            "Authorization": "Bearer 5d7caa7f1e33019f9b1851e179415bc9",
            "Content-Type": "application/json"
        },
        'json_payload': lambda q: {
            "url": f"https://{domain}/search?q={quote(q)}",
            "json": "2"
        }
    }


# ========== å•æ¬¡è¯·æ±‚ ==========
async def handle_request(session, semaphore, engine, term, req_num, ts_folder, logger):
    async with semaphore:
        config = build_service_config(engine)
        start_time = time.time()
        result = {
            'engine': engine,
            'term': term,
            'req_num': req_num,
            'success': False,
            'status_code': None,
            'error': '',
            'content_size_kb': 0,
            'elapsed_ms': 0,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

        try:
            async with session.request(
                method=config['method'],
                url=config['url'],
                headers=config.get('headers', {}),
                timeout=aiohttp.ClientTimeout(total=TIMEOUT_SECONDS),
                json=config['json_payload'](term)
            ) as response:

                content = await response.text()
                elapsed = (time.time() - start_time) * 1000
                result.update({
                    'status_code': response.status,
                    'elapsed_ms': elapsed,
                    'content_size_kb': len(content.encode('utf-8')) / 1024
                })

                logger.info(f"[{term}] çŠ¶æ€ç ={response.status}, è€—æ—¶={elapsed:.1f}ms, å¤§å°={result['content_size_kb']:.2f}KB")

                if "text/html" in response.headers.get("Content-Type", ""):
                    result['error'] = "è¿”å›äº† HTML é¡µé¢"
                    logger.info(f"â— {term} è¿”å› HTMLï¼Œè€—æ—¶={elapsed:.1f}ms")
                    return result

                if response.status != 200:
                    result['error'] = f"HTTPé”™è¯¯: {response.status}"
                    logger.info(f"â— {term} HTTPé”™è¯¯: {response.status}ï¼Œè€—æ—¶={elapsed:.1f}ms")
                    return result

                if not content:
                    result['error'] = "ç©ºå“åº”"
                    logger.info(f"â— {term} ç©ºå“åº”ï¼Œè€—æ—¶={elapsed:.1f}ms")
                    return result

                if result['content_size_kb'] < MIN_CONTENT_SIZE_KB:
                    result['error'] = f"å†…å®¹è¿‡å° ({result['content_size_kb']:.2f}KB)"
                    logger.info(f"â— {term} å†…å®¹è¿‡å°: {result['content_size_kb']:.2f}KBï¼Œè€—æ—¶={elapsed:.1f}ms")
                    return result

                if ENABLE_SAVE_RESPONSE:
                    folder = f"data/{engine}/{ts_folder}"
                    os.makedirs(folder, exist_ok=True)
                    filename = f"{term[:20].replace('/', '_')}_{req_num}_{int(time.time())}.txt"
                    with open(os.path.join(folder, filename), 'w', encoding='utf-8') as f:
                        f.write(content)

                result['success'] = True
                return result

        except asyncio.TimeoutError:
            elapsed = (time.time() - start_time) * 1000
            result['error'] = "è¯·æ±‚è¶…æ—¶"
            result['elapsed_ms'] = elapsed
            logger.info(f"â— {term} è¯·æ±‚è¶…æ—¶ï¼Œè€—æ—¶={elapsed:.1f}ms")
        except Exception as e:
            elapsed = (time.time() - start_time) * 1000
            result['error'] = f"å¼‚å¸¸: {str(e)}"
            result['elapsed_ms'] = elapsed
            logger.info(f"â— {term} å¼‚å¸¸: {str(e)}ï¼Œè€—æ—¶={elapsed:.1f}ms")

        return result


# ========== æ•°æ®ç»Ÿè®¡ ==========
def summarize_stats(engine, results):
    total = len(results)
    success = [r for r in results if r['success']]
    failed = [r for r in results if not r['success']]
    return {
        "engine": engine,
        "concurrency": CONCURRENCY,
        "total_requests": total,
        "success_count": len(success),
        "fail_count": len(failed),
        "success_rate": round(len(success) / total * 100, 2) if total else 0.0,
        "avg_elapsed_ms": round(mean(r['elapsed_ms'] for r in success), 2) if success else 0.0,
        "avg_size_kb": round(mean(r['content_size_kb'] for r in success), 2) if success else 0.0,
    }


# ========== é’‰é’‰é€šçŸ¥ ==========
async def send_dingtalk_report(summary_list):
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    lines = [f"### SERP {DINGTALK_KEYWORD} ç»“æœæ±‡æ€» - {now}"]
    for s in summary_list:
        lines.append(
            f"\n#### {s['engine'].upper()}\uff1a\n"
            f"- å¹¶å‘æ•°ï¼š{s['concurrency']}\n"
            f"- è¯·æ±‚æ•°ï¼š{s['total_requests']}\n"
            f"- æˆåŠŸæ•°ï¼š{s['success_count']}\n"
            f"- å¤±è´¥æ•°ï¼š{s['fail_count']}\n"
            f"- æˆåŠŸç‡ï¼š{s['success_rate']}%\n"
            f"- å¹³å‡è€—æ—¶ï¼š{s['avg_elapsed_ms']} ms\n"
            f"- å¹³å‡å¤§å°ï¼š{s['avg_size_kb']} KB\n"
        )

    payload = {
        "msgtype": "markdown",
        "markdown": {
            "title": f"{DINGTALK_KEYWORD} æ‰§è¡Œç»“æœ",
            "text": "\n".join(lines)
        }
    }

    async with aiohttp.ClientSession() as session:
        async with session.post(DINGTALK_WEBHOOK, json=payload) as resp:
            if resp.status != 200:
                log_print(f"âŒ é’‰é’‰é€šçŸ¥å¤±è´¥: {resp.status}")
            else:
                log_print("ğŸ“¢ é’‰é’‰é€šçŸ¥å·²å‘é€")


# ========== å•è½®æ‰§è¡Œ ==========
async def run_test_cycle():
    results_by_engine = []
    per_engine_duration = RUN_DURATION_SECONDS / len(SEARCH_ENGINES)
    ts_folder = datetime.now().strftime("%Y%m%d_%H%M%S")

    async with aiohttp.ClientSession() as session:
        for engine in SEARCH_ENGINES:
            log_print(f"\nâ–¶ å¼€å§‹å¼•æ“: {engine.upper()} (çº¦ {per_engine_duration:.1f}s)")
            end_time = time.time() + per_engine_duration
            semaphore = asyncio.Semaphore(CONCURRENCY)
            logger = get_engine_logger(engine, ts_folder)
            results = []
            req_num = 0

            while time.time() < end_time:
                tasks = []
                for term in SEARCH_TERMS:
                    req_num += 1
                    tasks.append(handle_request(session, semaphore, engine, term, req_num, ts_folder, logger))
                batch_results = await asyncio.gather(*tasks)
                results.extend(batch_results)

            summary = summarize_stats(engine, results)
            results_by_engine.append(summary)

    return results_by_engine


# ========== å‘¨æœŸæ‰§è¡Œ ==========
async def scheduled_loop():
    while True:
        log_print(f"\nâ±ï¸ å¼€å§‹æµ‹è¯•è½®æ¬¡: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        summary_list = await run_test_cycle()
        for s in summary_list:
            log_print(f"ğŸ“Š {s['engine'].upper()} ç»“æœ: {s}")
        await send_dingtalk_report(summary_list)
        log_print(f"\nâœ… å½“å‰è½®å®Œæˆï¼Œç­‰å¾… {SCHEDULE_INTERVAL} ç§’...\n")
        await asyncio.sleep(SCHEDULE_INTERVAL)


# ========== å¯åŠ¨ ==========
if __name__ == "__main__":
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    asyncio.run(scheduled_loop())
