import requests
import concurrent.futures
import csv
import gc
import time
import os
import threading
import random
import queue
from urllib.parse import quote
from collections import deque
from requests.adapters import HTTPAdapter
from threading import BoundedSemaphore

# ================== å…¨å±€é…ç½® ==================
DURATION = 0.02 * 60 * 60  # è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰æµ‹è¯•ç”¨60ç§’
MIN_CONTENT_LENGTH = 15 * 1024  # 15KBé˜ˆå€¼
CONCURRENCY = 50  # å¹¶å‘çº¿ç¨‹æ•°
MAX_REQUEST_TIMEOUT = 3.05 + 30  # æœ€å¤§è¯·æ±‚è¶…æ—¶æ—¶é—´
queries = [
    "pizza", "Apple", "Banana", "Bread", "Cake", "Cookie", "Egg", "Fish", "Meat", "Noodle",
    "Salad", "Soup", "Steak", "Taco",
    "Pasta", "Rice", "Burger", "Sushi", "Sandwich",
    "Pancake", "Waffle", "Yogurt", "Cheese", "Ham",
    "Sausage", "Chicken", "Turkey", "Dumpling",
    "Curry", "Tofu", "Omelette", "Pudding", "Pie"
]
STATS_INTERVAL = 1  # ç»Ÿè®¡æ˜¾ç¤ºé—´éš”
SERVICES_TO_RUN = ["thordata"]


# ================== å®æ—¶ç›‘æ§æ¨¡å— ==================
class LiveMonitor:
    def __init__(self, duration):
        self.queue = queue.Queue(maxsize=10000)
        self.start_time = time.time()
        self.duration = duration
        self.total = 0
        self.success = 0
        self.fail = 0
        self.latencies = deque(maxlen=500)
        self.success_latency_sum = 0
        self.success_count = 0
        self.last_total = 0
        self.last_time = self.start_time
        self._running = True
        self.process_thread = threading.Thread(target=self._process_queue, daemon=True)
        self.display_thread = threading.Thread(target=self._display_loop, daemon=True)
        self.process_thread.start()
        self.display_thread.start()

    def _process_queue(self):
        while self._running or not self.queue.empty():
            try:
                item = self.queue.get(timeout=0.5)
                if item['type'] == 'success':
                    self.total += 1
                    self.success += 1
                    self.success_latency_sum += item['latency']
                    self.success_count += 1
                    self.latencies.append(item['latency'])
                elif item['type'] == 'failure':
                    self.total += 1
                    self.fail += 1
                    self.latencies.append(item['latency'])
                self.queue.task_done()
            except queue.Empty:
                if not self._running:
                    break

    def _display_loop(self):
        while self._running:
            time.sleep(STATS_INTERVAL)
            self._print_stats()
        self._print_stats()  # æœ€ç»ˆè¾“å‡º

    def _print_stats(self):
        current_time = time.time()
        elapsed = current_time - self.start_time
        remaining = max(0, self.duration - elapsed)
        avg_latency = sum(self.latencies) / len(self.latencies) if self.latencies else 0

        time_diff = current_time - self.last_time
        current_total = self.total
        current_rps = (current_total - self.last_total) / time_diff if time_diff > 0 else 0
        self.last_total = current_total
        self.last_time = current_time

        avg_success = self.success_latency_sum / self.success_count if self.success_count else 0

        display = [
            "\n" + "=" * 50,
            f"å®æ—¶ç›‘æ§ @ {time.strftime('%Y-%m-%d %H:%M:%S')}",
            "-" * 50,
            f"è¿è¡Œæ—¶é—´: {self._format_duration(elapsed)} | å‰©ä½™æ—¶é—´: {self._format_duration(remaining)}",
            f"æ€»è¯·æ±‚é‡: {self.total} | æˆåŠŸ: {self.success} | å¤±è´¥: {self.fail}",
            f"æˆåŠŸç‡: {self.success / self.total * 100:.2f}%" if self.total else "æˆåŠŸç‡: N/A",
            f"å®æ—¶QPS: {current_rps:.2f}/s | å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms | å¹³å‡æˆåŠŸå»¶è¿Ÿ: {avg_success:.2f}ms",
            "=" * 50
        ]
        os.system('cls' if os.name == 'nt' else 'clear')
        print("\n".join(display))

    def _format_duration(self, seconds):
        hours, rem = divmod(seconds, 3600)
        minutes, seconds = divmod(rem, 60)
        return f"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}"

    def record_success(self, latency):
        self.queue.put({'type': 'success', 'latency': latency}, block=False)

    def record_failure(self, latency):
        self.queue.put({'type': 'failure', 'latency': latency}, block=False)

    def get_final_stats(self):
        if self.total == 0:
            return 0.0, 0.0
        success_rate = (self.success / self.total) * 100
        avg_success = self.success_latency_sum / self.success_count if self.success_count else 0.0
        return avg_success, success_rate

    def stop(self):
        self._running = False
        self.process_thread.join(timeout=2.0)
        self.display_thread.join(timeout=1.0)
        self.queue.join()


# ================== æ•°æ®è®°å½•æ¨¡å— ==================
class DataRecorder:
    def __init__(self, service_name):
        self.service = service_name
        os.makedirs(service_name, exist_ok=True)
        self.buffer = []
        self.buffer_size = 200
        self.buffer_lock = threading.Lock()
        self.csv_file = None
        self.closed = False  # æ–°å¢å…³é—­æ ‡å¿—
        self._init_file()

    def _init_file(self):
        self.csv_file = open(f'{self.service}/requests.csv', 'w', newline='', encoding='utf-8', buffering=2048)
        self.writer = csv.writer(self.csv_file)
        self.writer.writerow([
            'Timestamp', 'RequestID', 'Query',
            'Status', 'Latency(ms)', 'ContentLength', 'é”™è¯¯ä¿¡æ¯', 'AvgSuccessLatency(ms)', 'è¯·æ±‚æˆåŠŸç‡'
        ])

    def log_request(self, req_id, query, status, latency, length, error_info=""):
        if self.closed:  # æ£€æŸ¥æ˜¯å¦å·²å…³é—­
            return
        with self.buffer_lock:
            self.buffer.append((
                time.strftime('%Y-%m-%d %H:%M:%S'),
                req_id,
                query,
                'Success' if status else 'Failed',
                f"{latency:.2f}",
                length,
                error_info,
                "",
                ""
            ))
            if len(self.buffer) >= self.buffer_size:
                self._flush_buffer()

    def _flush_buffer(self):
        with self.buffer_lock:
            current_buffer = list(self.buffer)
            self.buffer.clear()
        for row in current_buffer:
            self.writer.writerow(row)
        self.csv_file.flush()

    def close(self, avg_success_latency, success_rate):
        self.closed = True  # æ ‡è®°å…³é—­çŠ¶æ€
        self._flush_buffer()
        if not self.csv_file.closed:
            self.csv_file.close()
        # é‡æ–°ä»¥è¿½åŠ æ¨¡å¼æ‰“å¼€æ–‡ä»¶å†™å…¥ç»Ÿè®¡æ•°æ®
        with open(f'{self.service}/requests.csv', 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(["", "", "", "", "", "", f"{avg_success_latency:.2f}", f"{success_rate:.2f}%"])


# ================== ä¿¡å·é‡å›è°ƒå¤„ç† ==================
def release_semaphore(future, semaphore):
    try:
        semaphore.release()
    except ValueError:
        pass  # å¿½ç•¥ä¿¡å·é‡è¶…è¿‡åˆå§‹å€¼çš„é”™è¯¯


# ================== æ–°å¢å…¨å±€å…³é—­åè°ƒå™¨ ==================
class ShutdownCoordinator:
    def __init__(self):
        self._event = threading.Event()
        self._lock = threading.Lock()
        self._active_connections = 0  # è·Ÿè¸ªè¿›è¡Œä¸­çš„ç½‘ç»œè¿æ¥

    def request_shutdown(self):
        """è§¦å‘ä¼˜é›…å…³é—­"""
        with self._lock:
            if not self._event.is_set():
                self._event.set()
                print("[SYSTEM] å…¨å±€å…³é—­ä¿¡å·å·²æ¿€æ´»")

    def should_stop(self):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢å½“å‰æ“ä½œ"""
        return self._event.is_set()

    def connection_enter(self):
        """æ³¨å†Œæ–°è¿æ¥"""
        with self._lock:
            self._active_connections += 1

    def connection_exit(self):
        """æ³¨é”€å®Œæˆè¿æ¥"""
        with self._lock:
            self._active_connections -= 1

    def active_connections(self):
        """è·å–å½“å‰æ´»è·ƒè¿æ¥æ•°"""
        with self._lock:
            return self._active_connections


# ================== è¯·æ±‚å¤„ç†æ¨¡å— ==================
def get_session():
    thread_local = threading.local()
    if not hasattr(thread_local, 'session'):
        session = requests.Session()
        adapter = HTTPAdapter(
            pool_connections=20,
            pool_maxsize=100,
        )
        session.mount('https://', adapter)
        session.mount('http://', adapter)
        thread_local.session = session
    return thread_local.session


def request_handler(service_name, req_id, query, monitor, recorder, shutdown_coord):
    """
    æ”¹è¿›åçš„è¯·æ±‚å¤„ç†å™¨ï¼Œæ”¯æŒï¼š
    - ä¼˜é›…å…³é—­ä¸­æ–­
    - è¿æ¥èµ„æºè·Ÿè¸ª
    - å¢å¼ºçš„é”™è¯¯å¤„ç†
    """
    # å‰ç½®å…³é—­æ£€æŸ¥
    if shutdown_coord.should_stop():
        recorder.log_request(req_id, query, False, 0, 0, "è¯·æ±‚è¢«å–æ¶ˆ(å‰ç½®æ£€æŸ¥)")
        return False

    session = None
    response = None
    start_time = time.time()
    latency = 0.0
    content_length = 0
    status_code = 0
    error_type = ""
    error_details = ""
    content_sample = []
    success = False

    try:
        # æ³¨å†Œè¿æ¥å¹¶è·å–ä¼šè¯
        shutdown_coord.connection_enter()
        session = get_session()

        # æ„å»ºè¯·æ±‚å‚æ•°
        if service_name == "brightdata":
            url = "https://api.brightdata.com/request"
            headers = {
                "Authorization": f"Bearer {os.getenv('BRIGHTDATA_API_KEY')}",
                "Content-Type": "application/json"
            }
            payload = {
                "zone": "serp_api1",
                "url": f"https://www.google.com/search?q={query}",
                "format": "json"
            }
            response = session.post(
                url,
                headers=headers,
                json=payload,
                timeout=(3.05, 30),
                stream=True
            )
        else:
            encoded_query = quote(f'https://www.google.com/search?q={query}', safe=':/?=')
            url = f"http://170.106.180.18:9004/spiders?search_url={encoded_query}"
            response = session.get(url, timeout=(3.05, 30), stream=True)

        # å¤„ç†å“åº”å†…å®¹ (æ”¯æŒä¸­æ–­çš„æµå¼è¯»å–)
        with response:
            status_code = response.status_code
            if status_code != 200:
                raise requests.exceptions.HTTPError(f"HTTP {status_code}")

            # åˆ†å—è¯»å–å†…å®¹å¹¶æ£€æŸ¥å…³é—­çŠ¶æ€
            for chunk in response.iter_content(chunk_size=4096):
                if shutdown_coord.should_stop():
                    raise RuntimeError("ä¸»åŠ¨ç»ˆæ­¢è¯·æ±‚æµ")

                content_length += len(chunk)
                if len(content_sample) < 4:  # é‡‡æ ·å‰4ä¸ªå—ï¼ˆçº¦16KBï¼‰
                    content_sample.append(chunk)

                # å†…å®¹é•¿åº¦é˜ˆå€¼æ£€æŸ¥
                if content_length > MIN_CONTENT_LENGTH * 2:  # æå‰ç»ˆæ­¢å¤§å“åº”
                    response.close()
                    break

            # éªŒè¯å†…å®¹å®Œæ•´æ€§
            if content_length < MIN_CONTENT_LENGTH:
                raise ValueError(f"å†…å®¹ä¸è¶³ {content_length}/{MIN_CONTENT_LENGTH} bytes")

            success = True

    except requests.exceptions.Timeout as e:
        error_type = "Timeout"
        error_details = f"{type(e).__name__} {str(e)}"
    except requests.exceptions.HTTPError as e:
        error_type = f"HTTP {status_code}"
        error_details = f"{response.text[:200]}" if response else "æ— å“åº”å†…å®¹"
    except requests.exceptions.RequestException as e:
        error_type = "NetworkError"
        error_details = f"{type(e).__name__} {str(e)}"
    except RuntimeError as e:
        if "ä¸»åŠ¨ç»ˆæ­¢è¯·æ±‚æµ" in str(e):
            error_type = "Shutdown"
            error_details = "ç¨‹åºå…³é—­æœŸé—´ç»ˆæ­¢"
        else:
            error_type = "RuntimeError"
            error_details = str(e)
    except Exception as e:
        error_type = "UnexpectedError"
        error_details = f"{type(e).__name__} {str(e)}"
    finally:
        try:
            # è®¡ç®—å»¶è¿Ÿ
            latency = (time.time() - start_time) * 1000  # æ¯«ç§’

            # èµ„æºæ¸…ç†
            if response:
                response.close()
            if session:
                session.close()
            shutdown_coord.connection_exit()

            # è®°å½•ç›‘æ§æ•°æ®
            if success:
                monitor.record_success(latency)
            else:
                monitor.record_failure(latency)

            # æ„å»ºé”™è¯¯æ—¥å¿—
            error_info = f"{error_type}: {error_details}" if error_type else ""
            if not success and not error_info:
                error_info = "æœªçŸ¥é”™è¯¯"

            # è®°å½•åˆ°CSV
            recorder.log_request(
                req_id=req_id,
                query=query,
                status=success,
                latency=latency,
                length=content_length,
                error_info=error_info[:200]  # é™åˆ¶é”™è¯¯ä¿¡æ¯é•¿åº¦
            )

            # ä¿å­˜è¯¦ç»†é”™è¯¯æ—¥å¿—
            if not success:
                save_error(
                    service=service_name,
                    query=query,
                    req_id=req_id,
                    status=status_code,
                    content=b''.join(content_sample).decode('utf-8', 'ignore')[:500],
                    exception=error_details
                )
        except Exception as inner_e:
            print(f"âš ï¸ åå¤„ç†é”™è¯¯: {str(inner_e)[:200]}")

    return success


def save_error(service, query, req_id, status, content, exception=None):
    error_dir = os.path.join(service, "errors")
    os.makedirs(error_dir, exist_ok=True)
    log_file = os.path.join(error_dir, f"errors_{time.strftime('%Y%m%d%H')}.log")

    with open(log_file, 'a', encoding='utf-8') as f:
        f.write(f"\n{'=' * 40}\n")
        f.write(f"Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Service: {service}\nRequestID: {req_id}\nQuery: {query}\n")
        if exception:
            f.write(f"Exception: {str(exception)[:200]}\n")
        else:
            safe_status = status if status is not None else "N/A"
            f.write(f"Status: {safe_status}\nContent Length: {len(content) if content else 0}\n")
        safe_content = content if isinstance(content, str) else str(content)
        f.write(f"Content Sample: {safe_content[:200]}...\n")


# ================== æœåŠ¡è¿è¡Œæ¨¡å— ==================
def run_service(service_name):
    print(f"\nâ–¶ å¯åŠ¨æœåŠ¡: {service_name.upper()}")
    monitor = LiveMonitor(DURATION)
    recorder = DataRecorder(service_name)
    shutdown_coord = ShutdownCoordinator()
    end_time = time.time() + DURATION
    req_id = 1

    with concurrent.futures.ThreadPoolExecutor(max_workers=CONCURRENCY) as executor:
        pending_sem = BoundedSemaphore(CONCURRENCY * 2)
        futures = set()

        try:
            while time.time() < end_time and not shutdown_coord.should_stop():
                # æµé‡æ§åˆ¶æ£€æŸ¥
                if pending_sem.acquire(blocking=False):
                    query = random.choice(queries)
                    future = executor.submit(
                        request_handler,
                        service_name,
                        req_id,
                        query,
                        monitor,
                        recorder,
                        shutdown_coord
                    )
                    req_id += 1
                    futures.add(future)
                    future.add_done_callback(lambda f: pending_sem.release())
                else:
                    time.sleep(0.01)

                # å®šæœŸæ¸…ç†å·²å®Œæˆä»»åŠ¡
                done = {f for f in futures if f.done()}
                futures -= done

                # åŠ¨æ€è°ƒæ•´æ£€æŸ¥é¢‘ç‡
                check_interval = max(0.1, len(futures) / CONCURRENCY * 0.05)
                time.sleep(check_interval)

        except KeyboardInterrupt:
            shutdown_coord.request_shutdown()

        finally:
            # ================== å››é˜¶æ®µå…³é—­æµç¨‹ ==================
            print("\nğŸ” è¿›å…¥ä¼˜é›…å…³é—­æµç¨‹...")

            # é˜¶æ®µ1: åœæ­¢æ–°è¯·æ±‚æäº¤
            shutdown_coord.request_shutdown()
            print(f"[å…³é—­é˜¶æ®µ1] åœæ­¢æ–°è¯·æ±‚ | æ´»è·ƒè¿æ¥: {shutdown_coord.active_connections()}")

            # é˜¶æ®µ2: å–æ¶ˆæœªå¼€å§‹ä»»åŠ¡
            canceled = 0
            for future in list(futures):
                if future.cancel():
                    futures.remove(future)
                    canceled += 1
            print(f"[å…³é—­é˜¶æ®µ2] å–æ¶ˆ{canceled}ä¸ªæœªå¼€å§‹ä»»åŠ¡ | å‰©ä½™ä»»åŠ¡: {len(futures)}")

            # é˜¶æ®µ3: ç­‰å¾…è¿›è¡Œä¸­ä»»åŠ¡ï¼ˆåˆ†çº§è¶…æ—¶ï¼‰
            shutdown_start = time.time()
            timeout_levels = [
                (5, "è€å¿ƒç­‰å¾…"),
                (10, "æ¸©å’Œå‚¬ä¿ƒ"),
                (15, "æœ€ç»ˆè­¦å‘Š"),
                (MAX_REQUEST_TIMEOUT, "å¼ºåˆ¶ç»ˆæ­¢")
            ]

            for timeout, stage_name in timeout_levels:
                print(f"[å…³é—­é˜¶æ®µ3-{stage_name}] æœ€å¤šç­‰å¾…{timeout}ç§’...")
                start_wait = time.time()
                while futures and (time.time() - start_wait < timeout):
                    done, _ = concurrent.futures.wait(
                        futures,
                        timeout=1,
                        return_when=concurrent.futures.FIRST_COMPLETED
                    )
                    for f in done:
                        futures.remove(f)
                    remaining = len(futures)
                    if remaining:
                        print(f"å‰©ä½™ä»»åŠ¡: {remaining} | æœ€é•¿ç­‰å¾…: {timeout - (time.time() - start_wait):.1f}s")
                    else:
                        break
                if not futures:
                    break

            # é˜¶æ®µ4: å¼ºåˆ¶ç»ˆæ­¢é¡½å›ºä»»åŠ¡
            if futures:
                print(f"[å…³é—­é˜¶æ®µ4] å¼ºåˆ¶ç»ˆæ­¢{len(futures)}ä¸ªé¡½å›ºä»»åŠ¡")
                for f in futures:
                    f.cancel()
                executor.shutdown(wait=False, cancel_futures=True)
                futures.clear()

    # æœ€ç»ˆå¤„ç†
    monitor.stop()
    avg_success, success_rate = monitor.get_final_stats()
    recorder.close(avg_success, success_rate)

    # è¿æ¥èµ„æºæœ€ç»ˆæ£€æŸ¥
    remaining_conns = shutdown_coord.active_connections()
    if remaining_conns > 0:
        print(f"âš ï¸ è­¦å‘Š: ä»æœ‰{remaining_conns}ä¸ªç½‘ç»œè¿æ¥æœªæ­£å¸¸å…³é—­")

    print(f"\nâœ… æœåŠ¡ {service_name.upper()} å…³é—­å®Œæˆ | ç»“æœä¿å­˜è‡³: {service_name}/")


# ================== ä¸»ç¨‹åºå…¥å£ ==================
if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘      åˆ†å¸ƒå¼å‹åŠ›æµ‹è¯•ç³»ç»Ÿ      â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    print(f"â€¢ è¿è¡Œæ—¶é•¿: {DURATION}ç§’")
    print(f"â€¢ å¹¶å‘çº¿ç¨‹: {CONCURRENCY}")
    print(f"â€¢ å†…å®¹é˜ˆå€¼: {MIN_CONTENT_LENGTH / 1024}KB")
    print(f"â€¢ ç›‘æ§é—´éš”: {STATS_INTERVAL}ç§’")
    print(f"â€¢ æµ‹è¯•æœåŠ¡: {', '.join(SERVICES_TO_RUN)}\n")

    start_time = time.time()
    for service in SERVICES_TO_RUN:
        run_service(service)
    total_time = time.time() - start_time

    print(f"\nâœ… æ‰€æœ‰æµ‹è¯•ä»»åŠ¡å®Œæˆï¼å®é™…è¿è¡Œæ—¶é—´: {total_time:.2f}ç§’ (é…ç½®: {DURATION}ç§’)")
    print(f"æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜åˆ°æœåŠ¡ç›®å½•çš„ requests.csv æ–‡ä»¶ä¸­")